{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "wsE4-Q5RQTPJ",
    "outputId": "51d4b843-6e79-421e-90f0-ea9c1f7960b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# SOLO PARA USO EN GOOGLE COLABORATORY\n",
    "# para conectar el notebook con la cuenta de gdrive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "!ls \"/content/drive/My Drive/\"\n",
    "BASE_FOLDER = '/content/drive/MyDrive/VIU/Docencia/MIAR_04_2021-22/07MAIR/' # Se debe garantizar que la carpeta docencia compartida se almacena en el directorio raíz de Google Drive. En caso contrario modificar este path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTUDtR1WkBfp",
    "outputId": "c286555d-dd42-40ff-df8e-2c391324f742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'[07MAIR_04_A_2018-19] Actividad1_corrección_1conv'\n",
      " 07MIAR_PracticaObservacional\n",
      " 07MIAR_Proyecto_Programacion\n",
      "'Actividad 1'\n",
      "'Cesión Derechos Imagen VIU.docx'\n",
      "'Colab Notebooks'\n",
      "'Docentes MAIR'\n",
      " HOLA.gdoc\n",
      " MAIR_MARKETING\n",
      " Panel_12_05_2020\n",
      " Redes_Neuronales.ipynb\n",
      " TFM_LauraVelaSampedro_21042021.pdf\n",
      " VIU\n"
     ]
    }
   ],
   "source": [
    "!ls \"/content/drive/MyDrive/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWnHIGKHsdq1"
   },
   "source": [
    "# 07MAIR - Redes Neuronales y Deep Learning\n",
    "## VC07: Más allá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySM6B3TpshO5"
   },
   "source": [
    "# Temas avanzados\n",
    "- Functional API: Desarrollo de redes neuronales avanzadas\n",
    " - Carga de datos desde Google Drive\n",
    " - Web scrapping empleando Bing Search API \n",
    "- Keras Tuner: Optimización automática de hiperparámetros\n",
    "- MLflow: Ciclo de vida de un modelo\n",
    "- Ir más allá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DB36wZd_tf-v"
   },
   "source": [
    "## Functional API\n",
    "- Hasta ahora hemos desarrollado redes neuronales secuenciales\n",
    "- Suficiente para muchos contextos, limitante para otros más complejos\n",
    " - Inputs independientes, múltiples outputs, ramificaciones internas, skip connections, retroalimentaciones, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_zPvc73tmE3"
   },
   "source": [
    "#### Ejemplo X input <-> 1 output: Predicción de precio de ropa de segunda mano\n",
    "\n",
    "- Inputs: metadata marca, tiempo usado (one hot encoded), foto (imagen), descripción (texto). \n",
    "- Modelo con tres submodelos (MLP para metadata, RNN para descripción a partir de texto, CNN para imagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "an8JNVGGtsBw"
   },
   "source": [
    "#### Ejemplo 1 input <-> X output: predicción de año de publicación y estilo de un libro\n",
    "\n",
    "- Un módulo con dos outputs (clasificadores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7N2m2n6t0q9"
   },
   "source": [
    "- Desventajas de la alternativa de construir modelos separados:\n",
    " - Coste computacional tanto en entrenamiento como en inferencia\n",
    " - No se tiene en cuenta toda la información a la vez y analizar la información de manera independiente produce sesgo\n",
    " - Se pierden las ventajas de un modelo entrenable end-to-end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-AG85ARE2rc"
   },
   "source": [
    "# Empleando la functional API: Red MISO CNN+MLP en HOUSE DATASET\n",
    "\n",
    "- Modelo con dos inputs (atributos y fotos)\n",
    "- Output: precio de las casas\n",
    "\n",
    "https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lObBVS9ahpuy"
   },
   "source": [
    "### Mis funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9yNNQPHE-c7"
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Filtrar las casas de codigos postales poco populares (menos de 10 casas)\n",
    "MIN_HOUSES_PER_ZIPCODE = 20\n",
    "# dimensiones de las imagenes (downsampling)\n",
    "IMAGE_DIM = (32,32)\n",
    "\n",
    "# Cargar los atributos del dataset\n",
    "def load_house_attributes(inputPath):\n",
    "        # Cargar el dataset con nombres especificados\n",
    "        cols = [\"bedrooms\", \"bathrooms\", \"area\", \"zipcode\", \"price\"]\n",
    "        df = pd.read_csv(inputPath, sep=\" \", header=None, names=cols)\n",
    "\n",
    "        # filtrar codigos postales con pocas casas\n",
    "        zipcodes = df[\"zipcode\"].value_counts().keys().tolist()\n",
    "        counts = df[\"zipcode\"].value_counts().tolist()\n",
    "\n",
    "        for (zipcode, count) in zip(zipcodes, counts):\n",
    "            if count < MIN_HOUSES_PER_ZIPCODE:\n",
    "                idxs = df[df[\"zipcode\"] == zipcode].index\n",
    "                df.drop(idxs, inplace=True)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZK3gW_SGBgn"
   },
   "outputs": [],
   "source": [
    "# Procesar los atributos\n",
    "def process_house_attributes(df, train, test):\n",
    "        # normalizar (valores 0 a 1) atributos continuos\n",
    "        continuous = [\"bedrooms\", \"bathrooms\", \"area\"]\n",
    "        cs = MinMaxScaler()\n",
    "        trainContinuous = cs.fit_transform(train[continuous])\n",
    "        testContinuous = cs.transform(test[continuous])\n",
    "\n",
    "        # one-hot encode el codigo postal\n",
    "        zipBinarizer = LabelBinarizer().fit(df[\"zipcode\"])\n",
    "        trainCategorical = zipBinarizer.transform(train[\"zipcode\"])\n",
    "        testCategorical = zipBinarizer.transform(test[\"zipcode\"])\n",
    "\n",
    "        # unir todos los atributos y dividir dataset\n",
    "        trainX = np.hstack([trainCategorical, trainContinuous])\n",
    "        testX = np.hstack([testCategorical, testContinuous])\n",
    "\n",
    "        return (trainX, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfcnGa0pGF7n"
   },
   "outputs": [],
   "source": [
    "# Cargar imagenes\n",
    "def load_house_images(df, inputPath):\n",
    "        images = []\n",
    "\n",
    "        # cada linea es un data point\n",
    "        for i in df.index.values:\n",
    "            # cargar las cuatro imagenes por casa\n",
    "            basePath = os.path.sep.join([inputPath, \"{}_*\".format(i + 1)])\n",
    "            housePaths = sorted(list(glob.glob(basePath)))\n",
    "            inputImages = []\n",
    "            outputImage = np.zeros((IMAGE_DIM[0] * 2, IMAGE_DIM[1] * 2, 3), dtype=\"uint8\")\n",
    "\n",
    "            # por cada imagen, redimensionar \n",
    "            for housePath in housePaths:\n",
    "                # load the input image, resize it to be 32 32, and then\n",
    "                # update the list of input images\n",
    "                image = cv2.imread(housePath)\n",
    "                image = cv2.resize(image, IMAGE_DIM)\n",
    "                inputImages.append(image)\n",
    "\n",
    "            # tile the four input images in the output image such the first\n",
    "            # image goes in the top-right corner, the second image in the\n",
    "            # top-left corner, the third image in the bottom-right corner,\n",
    "            # and the final image in the bottom-left corner\n",
    "            outputImage[0:IMAGE_DIM[0], 0:IMAGE_DIM[1]] = inputImages[0]\n",
    "            outputImage[0:IMAGE_DIM[0], IMAGE_DIM[1]:IMAGE_DIM[1]*2] = inputImages[1]\n",
    "            outputImage[IMAGE_DIM[0]:IMAGE_DIM[0]*2, IMAGE_DIM[1]:IMAGE_DIM[1]*2] = inputImages[2]\n",
    "            outputImage[IMAGE_DIM[0]:IMAGE_DIM[0]*2, 0:IMAGE_DIM[1]] = inputImages[3]\n",
    "\n",
    "            # add the tiled image to our set of images the network will be\n",
    "            # trained on\n",
    "            images.append(outputImage)\n",
    "\n",
    "        # return our set of images\n",
    "        return np.array(images) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJPLyKg1hV_r"
   },
   "source": [
    "### Creando la rama MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmIRpa5fGYAg"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D, BatchNormalization, MaxPooling2D, Activation, concatenate\n",
    "\n",
    "# Creacion del modelo MLP (para los atributos numericos)\n",
    "def create_mlp(dim, regress=False):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
    "        model.add(Dense(4, activation=\"relu\"))\n",
    "\n",
    "        # check to see if the regression node should be added\n",
    "        if regress:\n",
    "            model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "        # return our model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeCaiPyshaoz"
   },
   "source": [
    "### Creando la rama CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGY7noznGogF"
   },
   "outputs": [],
   "source": [
    "# Crear el modelo CNN\n",
    "def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False):\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "\n",
    "        # define the model input\n",
    "        inputs = Input(shape=inputShape)\n",
    "\n",
    "        # crear tantas capas como filtros pasados\n",
    "        for (i, f) in enumerate(filters):\n",
    "            if i == 0:\n",
    "                x = inputs\n",
    "\n",
    "            # CONV => RELU => BN => POOL\n",
    "            x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "            x = Activation(\"relu\")(x)\n",
    "            x = BatchNormalization(axis=chanDim)(x)\n",
    "            x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        \n",
    "        # Top model\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "\n",
    "        # Middle output layer\n",
    "        x = Dense(4)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "\n",
    "        # Check to see if the regression node should be added\n",
    "        if regress:\n",
    "            x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "        model = Model(inputs, x)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IcPheskgcKQ"
   },
   "source": [
    "### Importando datos desde Google Drive: House Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zfKWikTiCb-"
   },
   "outputs": [],
   "source": [
    "# SOLO PARA USO EN GOOGLE COLABORATORY\n",
    "# para conectar el notebook con la cuenta de gdrive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "#!ls \"/content/drive/My Drive/\"\n",
    "BASE_FOLDER = '/content/drive/My Drive/07MAIR_0420/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "hhTYmtLgG3E0",
    "outputId": "d2804f93-767d-4769-a6e6-6a30048cd31b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando atributoss...\n",
      "[INFO] loading house images...\n"
     ]
    }
   ],
   "source": [
    "# Cargar los atributos numericos\n",
    "print('Cargando atributoss...')\n",
    "inputPath = BASE_FOLDER+'resources/Houses-dataset/HousesInfo.txt'\n",
    "df = load_house_attributes(inputPath)\n",
    "\n",
    "# Cargar imágenes\n",
    "print(\"[INFO] loading house images...\")\n",
    "images = load_house_images(df, BASE_FOLDER+'resources/Houses-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "DNgo41fUk8L6",
    "outputId": "de1f25a1-7416-43cf-8da7-be8144989c99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 64, 64, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLOEcvWNhQMO"
   },
   "source": [
    "### Acondicionamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zMlkb-9G3_K"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir imagenes en train y test\n",
    "split = train_test_split(df, images, test_size=0.25, random_state=42)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split\n",
    "\n",
    "# Normalizar el precio de las casas\n",
    "maxPrice = trainAttrX[\"price\"].max()\n",
    "trainY = trainAttrX[\"price\"] / maxPrice\n",
    "testY = testAttrX[\"price\"] / maxPrice\n",
    "\n",
    "# Procesar atributos numericos\n",
    "(trainAttrX, testAttrX) = process_house_attributes(df,trainAttrX, testAttrX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59jasLBQgWzG"
   },
   "source": [
    "### Construcción del modelo híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5GXRNtoG6yK"
   },
   "outputs": [],
   "source": [
    "# Crear los dos modelos (MLP y CNN)\n",
    "mlp = create_mlp(trainAttrX.shape[1], regress=False)\n",
    "cnn = create_cnn(IMAGE_DIM[0] * 2, IMAGE_DIM[1]*2, 3, regress=False)\n",
    "\n",
    "# Unir ambas ramas en una única de salida (concatenarlos)\n",
    "combinedInput = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "# Clasificador final tras la concatenacion\n",
    "x = Dense(4, activation=\"relu\")(combinedInput)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "# Construir el modelo final\n",
    "model = Model(inputs=[mlp.input, cnn.input], outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OG8rTrv9f3MJ"
   },
   "source": [
    "### Compilación y entrenamiento de nuestra red MISO híbrida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8LnUfijxG9pH",
    "outputId": "fc848a2f-8bdf-4c16-8257-fdb380aa8479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenar el modelo...\n",
      "Train on 288 samples, validate on 96 samples\n",
      "Epoch 1/50\n",
      "288/288 [==============================] - 4s 12ms/sample - loss: 1058.0105 - val_loss: 697.4843\n",
      "Epoch 2/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 702.0007 - val_loss: 220.6218\n",
      "Epoch 3/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 619.5501 - val_loss: 224.6528\n",
      "Epoch 4/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 446.5802 - val_loss: 241.4039\n",
      "Epoch 5/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 343.1163 - val_loss: 213.5732\n",
      "Epoch 6/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 307.4464 - val_loss: 143.5633\n",
      "Epoch 7/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 216.2664 - val_loss: 168.7331\n",
      "Epoch 8/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 237.6755 - val_loss: 181.7929\n",
      "Epoch 9/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 171.1048 - val_loss: 123.7346\n",
      "Epoch 10/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 161.3895 - val_loss: 123.0261\n",
      "Epoch 11/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 161.1767 - val_loss: 129.7954\n",
      "Epoch 12/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 149.7940 - val_loss: 97.8922\n",
      "Epoch 13/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 111.5875 - val_loss: 80.3869\n",
      "Epoch 14/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 101.5946 - val_loss: 83.0598\n",
      "Epoch 15/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 118.2108 - val_loss: 67.3131\n",
      "Epoch 16/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 97.6585 - val_loss: 69.3508\n",
      "Epoch 17/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 105.3505 - val_loss: 74.3702\n",
      "Epoch 18/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 109.4004 - val_loss: 73.0377\n",
      "Epoch 19/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 84.7919 - val_loss: 55.4323\n",
      "Epoch 20/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 91.9964 - val_loss: 55.8533\n",
      "Epoch 21/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 76.8577 - val_loss: 47.6653\n",
      "Epoch 22/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 82.2582 - val_loss: 45.9067\n",
      "Epoch 23/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 70.0957 - val_loss: 44.6309\n",
      "Epoch 24/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 70.4806 - val_loss: 42.6487\n",
      "Epoch 25/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 72.7143 - val_loss: 40.3677\n",
      "Epoch 26/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 56.4553 - val_loss: 39.8466\n",
      "Epoch 27/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 55.3821 - val_loss: 38.2302\n",
      "Epoch 28/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 59.4435 - val_loss: 36.7895\n",
      "Epoch 29/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 52.9786 - val_loss: 38.5670\n",
      "Epoch 30/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 48.6526 - val_loss: 39.2594\n",
      "Epoch 31/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 50.8622 - val_loss: 39.4350\n",
      "Epoch 32/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 52.4340 - val_loss: 36.7882\n",
      "Epoch 33/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 50.4713 - val_loss: 36.5957\n",
      "Epoch 34/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 38.5706 - val_loss: 34.2493\n",
      "Epoch 35/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 40.3991 - val_loss: 34.3749\n",
      "Epoch 36/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 40.1030 - val_loss: 31.5306\n",
      "Epoch 37/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 39.3350 - val_loss: 32.7150\n",
      "Epoch 38/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 37.0972 - val_loss: 33.7557\n",
      "Epoch 39/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 32.8182 - val_loss: 32.7397\n",
      "Epoch 40/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 33.7587 - val_loss: 30.8959\n",
      "Epoch 41/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 30.3741 - val_loss: 28.9837\n",
      "Epoch 42/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 33.4482 - val_loss: 29.2734\n",
      "Epoch 43/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 29.2665 - val_loss: 27.7499\n",
      "Epoch 44/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 28.7456 - val_loss: 28.8850\n",
      "Epoch 45/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 27.2256 - val_loss: 26.7590\n",
      "Epoch 46/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 30.5482 - val_loss: 27.3641\n",
      "Epoch 47/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 27.9876 - val_loss: 31.0481\n",
      "Epoch 48/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 28.7952 - val_loss: 27.1178\n",
      "Epoch 49/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 29.8883 - val_loss: 26.9693\n",
      "Epoch 50/50\n",
      "288/288 [==============================] - 3s 9ms/sample - loss: 28.3313 - val_loss: 29.0179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f459f5d7fd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# utilizamos el optimizador Adam (con learning rate adaptativo)\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
    "\n",
    "# entrenar\n",
    "print(\"Entrenar el modelo...\")\n",
    "H = model.fit([trainAttrX, trainImagesX], trainY,\n",
    "        validation_data=([testAttrX, testImagesX], testY),\n",
    "        epochs=50, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPZCeznigBrz"
   },
   "source": [
    "### Evaluando el performance del modelo en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "RGA_toh-G_1S",
    "outputId": "e8c5f3bb-5eea-4a66-986f-34920d68fcd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones...\n",
      "Precio medio: 527956.125. STD: 479979.80059985846\n",
      "[INFO] mean: 29.02%, std: 33.08\n"
     ]
    }
   ],
   "source": [
    "# Predicciones en test\n",
    "print(\"Predicciones...\")\n",
    "preds = model.predict([testAttrX, testImagesX])\n",
    "\n",
    "# calcular el error (entre lo predicho y lo esperado)\n",
    "diff = preds.flatten() - testY\n",
    "percentDiff = (diff / testY) * 100\n",
    "absPercentDiff = np.abs(percentDiff)\n",
    "\n",
    "# calcular el error medio y su std\n",
    "mean = np.mean(absPercentDiff)\n",
    "std = np.std(absPercentDiff)\n",
    "\n",
    "# resultados finales\n",
    "print(\"Precio medio: {}. STD: {}\".format(df[\"price\"].mean(),df[\"price\"].std()))\n",
    "print(\"[INFO] mean: {:.2f}%, std: {:.2f}\".format(mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUAv4idMHOwF"
   },
   "source": [
    "#### Ejercicios\n",
    "\n",
    "- Calcular la misma métrica para el modelo MLP solamente \n",
    " - ¿Obtenemos mejores o peores resultados sin las imágenes?\n",
    "- Data augmentation para incrementar los data points (¡pocos!)\n",
    "- Visualizar los filtros y las activaciones máximas del modelo CNN\n",
    " - ¿Se está utilizando de forma efectiva?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpaLBlQthJNj"
   },
   "source": [
    "### *Keys and Tricks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nrLT5LagpTl"
   },
   "source": [
    "- Creación de un dataset propio a partir de imágenes en la red: \n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/bing-image-search/quickstarts/python\n",
    "\n",
    "- Custom data generator para la lectura de imágenes/datos:\n",
    "https://towardsdatascience.com/implementing-custom-data-generators-in-keras-de56f013581c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2w7gWaFh2Wr"
   },
   "source": [
    "# Empleando la functional API para el desarrollo de una residual CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIFarnV0DfMz"
   },
   "outputs": [],
   "source": [
    "# Definition of the CNN with residual connections\n",
    "NB_Antennas = 16\n",
    "nn_input  = Input((Nb_Antennas,924,2))\n",
    "nn_input_shortcut = nn_input\n",
    "\n",
    "# 1st RESIDUAL BLOCK\n",
    "nn_output = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(nn_input)\n",
    "nn_output = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(nn_output)\n",
    "nn_output = Conv2D(32, (3, 3), padding=\"same\")(nn_output)\n",
    "nn_input_shortcut = Conv2D(32, (3, 3), padding=\"same\")(nn_input_shortcut)\n",
    "nn_output = Add()([nn_output, nn_input_shortcut])\n",
    "nn_output = Activation('relu')(nn_output)\n",
    "nn_output = AveragePooling2D(pool_size=(1, 4))(nn_output)\n",
    "nn_output_shortcut = nn_output\n",
    "\n",
    "# 2nd RESIDUAL BLOCK\n",
    "nn_output = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(nn_output)\n",
    "nn_output = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(nn_output)\n",
    "nn_output = Conv2D(32, (3, 3), padding=\"same\")(nn_output)\n",
    "nn_output_shortcut = Conv2D(32, (3, 3), padding=\"same\")(nn_output_shortcut)\n",
    "nn_output = Add()([nn_output, nn_output_shortcut])\n",
    "nn_output = Activation('relu')(nn_output)\n",
    "nn_output = AveragePooling2D(pool_size=(1, 4))(nn_output)\n",
    "\n",
    "# TOP MODEL\n",
    "nn_output = Flatten()(nn_output)\n",
    "nn_output = Dense(128, activation='relu')(nn_output)\n",
    "nn_output = Dense(128, activation='relu')(nn_output)\n",
    "nn_output = Dropout(0.25)(nn_output)\n",
    "nn_output = Dense(128, activation='relu')(nn_output)\n",
    "nn_output = Dropout(0.5)(nn_output)\n",
    "nn_output = Dense(3, activation='linear')(nn_output)\n",
    "nn = Model(inputs=nn_input, outputs=nn_output)\n",
    "nn.compile(optimizer='Adam', loss='mse', metrics=[dist])\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcNbPlTkO8gm"
   },
   "source": [
    "# Keras Tuner: Optimización de hiperparámetros\n",
    "\n",
    "Keras Tuner es una librería que ayuda a elegir el conjunto óptimo de hiperparámetros de manera automática. El proceso de seleccionar el conjunto correcto de hiperparámetros para un algoritmo de aprendizaje automático ajuste de hiperparámetros o *hypertuning*.\n",
    "Existen dos tipos de hiperparámetros:\n",
    "- **Hiperparámetros de modelo**: Influyen en la selección del modelo, como el número y el ancho de las capas ocultas.\n",
    "\n",
    "- **Hiperparámetros de algoritmo**: Influyen en la velocidad y la calidad del algoritmo de aprendizaje, p.ejem. la tasa de aprendizaje para el descenso de gradiente estocástico (SGD) y el número de vecinos más cercanos para un clasificador KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VecTRr7cqRK"
   },
   "source": [
    "### Instalamos Keras Tuner y cargamos dataset fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ocAn6rVfO73h",
    "outputId": "b4cda855-0895-40ff-b1d1-c276061fbd0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.10.0\n",
      "alabaster==0.7.12\n",
      "albumentations==0.1.12\n",
      "altair==4.1.0\n",
      "argon2-cffi==20.1.0\n",
      "asgiref==3.2.10\n",
      "astor==0.8.1\n",
      "astropy==4.0.1.post1\n",
      "astunparse==1.6.3\n",
      "async-generator==1.10\n",
      "atari-py==0.2.6\n",
      "atomicwrites==1.4.0\n",
      "attrs==20.2.0\n",
      "audioread==2.1.8\n",
      "autograd==1.3\n",
      "Babel==2.8.0\n",
      "backcall==0.2.0\n",
      "beautifulsoup4==4.6.3\n",
      "bleach==3.2.0\n",
      "blis==0.4.1\n",
      "bokeh==2.1.1\n",
      "boto==2.49.0\n",
      "boto3==1.14.63\n",
      "botocore==1.17.63\n",
      "Bottleneck==1.3.2\n",
      "branca==0.4.1\n",
      "bs4==0.0.1\n",
      "CacheControl==0.12.6\n",
      "cachetools==4.1.1\n",
      "catalogue==1.0.0\n",
      "certifi==2020.6.20\n",
      "cffi==1.14.2\n",
      "chainer==7.4.0\n",
      "chardet==3.0.4\n",
      "click==7.1.2\n",
      "cloudpickle==1.3.0\n",
      "cmake==3.12.0\n",
      "cmdstanpy==0.9.5\n",
      "colorama==0.4.3\n",
      "colorlover==0.3.0\n",
      "community==1.0.0b1\n",
      "contextlib2==0.5.5\n",
      "convertdate==2.2.2\n",
      "coverage==3.7.1\n",
      "coveralls==0.5\n",
      "crcmod==1.7\n",
      "cufflinks==0.17.3\n",
      "cupy-cuda101==7.4.0\n",
      "cvxopt==1.2.5\n",
      "cvxpy==1.0.31\n",
      "cycler==0.10.0\n",
      "cymem==2.0.3\n",
      "Cython==0.29.21\n",
      "daft==0.0.4\n",
      "dask==2.12.0\n",
      "dataclasses==0.7\n",
      "datascience==0.10.6\n",
      "debugpy==1.0.0rc2\n",
      "decorator==4.4.2\n",
      "defusedxml==0.6.0\n",
      "descartes==1.1.0\n",
      "dill==0.3.2\n",
      "distributed==1.25.3\n",
      "Django==3.1.1\n",
      "dlib==19.18.0\n",
      "dm-tree==0.1.5\n",
      "docopt==0.6.2\n",
      "docutils==0.15.2\n",
      "dopamine-rl==1.0.5\n",
      "earthengine-api==0.1.235\n",
      "easydict==1.9\n",
      "ecos==2.0.7.post1\n",
      "editdistance==0.5.3\n",
      "en-core-web-sm==2.2.5\n",
      "entrypoints==0.3\n",
      "ephem==3.7.7.1\n",
      "et-xmlfile==1.0.1\n",
      "fa2==0.3.5\n",
      "fancyimpute==0.4.3\n",
      "fastai==1.0.61\n",
      "fastdtw==0.3.4\n",
      "fastprogress==1.0.0\n",
      "fastrlock==0.5\n",
      "fbprophet==0.7.1\n",
      "feather-format==0.4.1\n",
      "filelock==3.0.12\n",
      "firebase-admin==4.4.0\n",
      "fix-yahoo-finance==0.0.22\n",
      "Flask==1.1.2\n",
      "folium==0.8.3\n",
      "future==0.16.0\n",
      "gast==0.3.3\n",
      "GDAL==2.2.2\n",
      "gdown==3.6.4\n",
      "gensim==3.6.0\n",
      "geographiclib==1.50\n",
      "geopy==1.17.0\n",
      "gin-config==0.3.0\n",
      "glob2==0.7\n",
      "google==2.0.3\n",
      "google-api-core==1.16.0\n",
      "google-api-python-client==1.7.12\n",
      "google-auth==1.17.2\n",
      "google-auth-httplib2==0.0.4\n",
      "google-auth-oauthlib==0.4.1\n",
      "google-cloud-bigquery==1.21.0\n",
      "google-cloud-core==1.0.3\n",
      "google-cloud-datastore==1.8.0\n",
      "google-cloud-firestore==1.7.0\n",
      "google-cloud-language==1.2.0\n",
      "google-cloud-storage==1.18.1\n",
      "google-cloud-translate==1.5.0\n",
      "google-colab==1.0.0\n",
      "google-pasta==0.2.0\n",
      "google-resumable-media==0.4.1\n",
      "googleapis-common-protos==1.52.0\n",
      "googledrivedownloader==0.4\n",
      "graphviz==0.10.1\n",
      "grpcio==1.32.0\n",
      "gspread==3.0.1\n",
      "gspread-dataframe==3.0.8\n",
      "gym==0.17.2\n",
      "h5py==2.10.0\n",
      "HeapDict==1.0.1\n",
      "holidays==0.10.3\n",
      "holoviews==1.13.4\n",
      "html5lib==1.0.1\n",
      "httpimport==0.5.18\n",
      "httplib2==0.17.4\n",
      "httplib2shim==0.0.3\n",
      "humanize==0.5.1\n",
      "hyperopt==0.1.2\n",
      "ideep4py==2.0.0.post3\n",
      "idna==2.10\n",
      "image==1.5.32\n",
      "imageio==2.4.1\n",
      "imagesize==1.2.0\n",
      "imbalanced-learn==0.4.3\n",
      "imblearn==0.0\n",
      "imgaug==0.2.9\n",
      "importlib-metadata==1.7.0\n",
      "imutils==0.5.3\n",
      "inflect==2.1.0\n",
      "iniconfig==1.0.1\n",
      "intel-openmp==2020.0.133\n",
      "intervaltree==2.1.0\n",
      "ipykernel==4.10.1\n",
      "ipython==5.5.0\n",
      "ipython-genutils==0.2.0\n",
      "ipython-sql==0.3.9\n",
      "ipywidgets==7.5.1\n",
      "itsdangerous==1.1.0\n",
      "jax==0.1.75\n",
      "jaxlib==0.1.52\n",
      "jdcal==1.4.1\n",
      "jedi==0.17.2\n",
      "jieba==0.42.1\n",
      "Jinja2==2.11.2\n",
      "jmespath==0.10.0\n",
      "joblib==0.16.0\n",
      "jpeg4py==0.1.4\n",
      "jsonschema==2.6.0\n",
      "jupyter==1.0.0\n",
      "jupyter-client==5.3.5\n",
      "jupyter-console==5.2.0\n",
      "jupyter-core==4.6.3\n",
      "jupyterlab-pygments==0.1.1\n",
      "kaggle==1.5.8\n",
      "kapre==0.1.3.1\n",
      "Keras==2.4.3\n",
      "Keras-Preprocessing==1.1.2\n",
      "keras-tuner==1.0.1\n",
      "keras-vis==0.4.1\n",
      "kiwisolver==1.2.0\n",
      "knnimpute==0.1.0\n",
      "korean-lunar-calendar==0.2.1\n",
      "librosa==0.6.3\n",
      "lightgbm==2.2.3\n",
      "llvmlite==0.31.0\n",
      "lmdb==0.99\n",
      "lucid==0.3.8\n",
      "LunarCalendar==0.0.9\n",
      "lxml==4.2.6\n",
      "Markdown==3.2.2\n",
      "MarkupSafe==1.1.1\n",
      "matplotlib==3.2.2\n",
      "matplotlib-venn==0.11.5\n",
      "missingno==0.4.2\n",
      "mistune==0.8.4\n",
      "mizani==0.6.0\n",
      "mkl==2019.0\n",
      "mlxtend==0.14.0\n",
      "more-itertools==8.5.0\n",
      "moviepy==0.2.3.5\n",
      "mpmath==1.1.0\n",
      "msgpack==1.0.0\n",
      "multiprocess==0.70.10\n",
      "multitasking==0.0.9\n",
      "murmurhash==1.0.2\n",
      "music21==5.5.0\n",
      "natsort==5.5.0\n",
      "nbclient==0.5.0\n",
      "nbconvert==5.6.1\n",
      "nbformat==5.0.7\n",
      "nest-asyncio==1.4.0\n",
      "networkx==2.5\n",
      "nibabel==3.0.2\n",
      "nltk==3.2.5\n",
      "notebook==5.3.1\n",
      "np-utils==0.5.12.1\n",
      "numba==0.48.0\n",
      "numexpr==2.7.1\n",
      "numpy==1.18.5\n",
      "nvidia-ml-py3==7.352.0\n",
      "oauth2client==4.1.3\n",
      "oauthlib==3.1.0\n",
      "okgrade==0.4.3\n",
      "opencv-contrib-python==4.1.2.30\n",
      "opencv-python==4.1.2.30\n",
      "openpyxl==2.5.9\n",
      "opt-einsum==3.3.0\n",
      "osqp==0.6.1\n",
      "packaging==20.4\n",
      "palettable==3.3.0\n",
      "pandas==1.0.5\n",
      "pandas-datareader==0.8.1\n",
      "pandas-gbq==0.11.0\n",
      "pandas-profiling==1.4.1\n",
      "pandocfilters==1.4.2\n",
      "panel==0.9.7\n",
      "param==1.9.3\n",
      "parso==0.7.1\n",
      "pathlib==1.0.1\n",
      "patsy==0.5.1\n",
      "pexpect==4.8.0\n",
      "pickleshare==0.7.5\n",
      "Pillow==7.0.0\n",
      "pip-tools==4.5.1\n",
      "plac==1.1.3\n",
      "plotly==4.4.1\n",
      "plotnine==0.6.0\n",
      "pluggy==0.7.1\n",
      "portpicker==1.3.1\n",
      "prefetch-generator==1.0.1\n",
      "preshed==3.0.2\n",
      "prettytable==0.7.2\n",
      "progressbar2==3.38.0\n",
      "prometheus-client==0.8.0\n",
      "promise==2.3\n",
      "prompt-toolkit==1.0.18\n",
      "protobuf==3.12.4\n",
      "psutil==5.4.8\n",
      "psycopg2==2.7.6.1\n",
      "ptyprocess==0.6.0\n",
      "py==1.9.0\n",
      "pyarrow==0.14.1\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycocotools==2.0.2\n",
      "pycparser==2.20\n",
      "pyct==0.4.8\n",
      "pydata-google-auth==1.1.0\n",
      "pydot==1.3.0\n",
      "pydot-ng==2.0.0\n",
      "pydotplus==2.0.2\n",
      "PyDrive==1.3.1\n",
      "pyemd==0.5.1\n",
      "pyglet==1.5.0\n",
      "Pygments==2.6.1\n",
      "pygobject==3.26.1\n",
      "pymc3==3.7\n",
      "PyMeeus==0.3.7\n",
      "pymongo==3.11.0\n",
      "pymystem3==0.2.0\n",
      "PyOpenGL==3.1.5\n",
      "pyparsing==2.4.7\n",
      "pyrsistent==0.17.3\n",
      "pysndfile==1.3.8\n",
      "PySocks==1.7.1\n",
      "pystan==2.19.1.1\n",
      "pytest==3.6.4\n",
      "python-apt==1.6.5+ubuntu0.3\n",
      "python-chess==0.23.11\n",
      "python-dateutil==2.8.1\n",
      "python-louvain==0.14\n",
      "python-slugify==4.0.1\n",
      "python-utils==2.4.0\n",
      "pytz==2018.9\n",
      "pyviz-comms==0.7.6\n",
      "PyWavelets==1.1.1\n",
      "PyYAML==3.13\n",
      "pyzmq==19.0.2\n",
      "qtconsole==4.7.7\n",
      "QtPy==1.9.0\n",
      "regex==2019.12.20\n",
      "requests==2.23.0\n",
      "requests-oauthlib==1.3.0\n",
      "resampy==0.2.2\n",
      "retrying==1.3.3\n",
      "rpy2==3.2.7\n",
      "rsa==4.6\n",
      "s3transfer==0.3.3\n",
      "scikit-image==0.16.2\n",
      "scikit-learn==0.22.2.post1\n",
      "scipy==1.4.1\n",
      "screen-resolution-extra==0.0.0\n",
      "scs==2.1.2\n",
      "seaborn==0.10.1\n",
      "Send2Trash==1.5.0\n",
      "setuptools-git==1.2\n",
      "Shapely==1.7.1\n",
      "simplegeneric==0.8.1\n",
      "six==1.15.0\n",
      "sklearn==0.0\n",
      "sklearn-pandas==1.8.0\n",
      "slugify==0.0.1\n",
      "smart-open==2.1.1\n",
      "snowballstemmer==2.0.0\n",
      "sortedcontainers==2.2.2\n",
      "spacy==2.2.4\n",
      "Sphinx==1.8.5\n",
      "sphinxcontrib-serializinghtml==1.1.4\n",
      "sphinxcontrib-websupport==1.2.4\n",
      "SQLAlchemy==1.3.19\n",
      "sqlparse==0.3.1\n",
      "srsly==1.0.2\n",
      "statsmodels==0.10.2\n",
      "sympy==1.1.1\n",
      "tables==3.4.4\n",
      "tabulate==0.8.7\n",
      "tblib==1.7.0\n",
      "tensorboard==2.3.0\n",
      "tensorboard-plugin-wit==1.7.0\n",
      "tensorboardcolab==0.0.22\n",
      "tensorflow==2.3.0\n",
      "tensorflow-addons==0.8.3\n",
      "tensorflow-datasets==2.1.0\n",
      "tensorflow-estimator==2.3.0\n",
      "tensorflow-gcs-config==2.3.0\n",
      "tensorflow-hub==0.9.0\n",
      "tensorflow-metadata==0.24.0\n",
      "tensorflow-privacy==0.2.2\n",
      "tensorflow-probability==0.11.0\n",
      "termcolor==1.1.0\n",
      "terminado==0.8.3\n",
      "terminaltables==3.1.0\n",
      "testpath==0.4.4\n",
      "text-unidecode==1.3\n",
      "textblob==0.15.3\n",
      "textgenrnn==1.4.1\n",
      "Theano==1.0.5\n",
      "thinc==7.4.0\n",
      "tifffile==2020.9.3\n",
      "toml==0.10.1\n",
      "toolz==0.10.0\n",
      "torch==1.6.0+cu101\n",
      "torchsummary==1.5.1\n",
      "torchtext==0.3.1\n",
      "torchvision==0.7.0+cu101\n",
      "tornado==5.1.1\n",
      "tqdm==4.41.1\n",
      "traitlets==4.3.3\n",
      "tweepy==3.6.0\n",
      "typeguard==2.7.1\n",
      "typing-extensions==3.7.4.3\n",
      "tzlocal==1.5.1\n",
      "umap-learn==0.4.6\n",
      "uritemplate==3.0.1\n",
      "urllib3==1.24.3\n",
      "vega-datasets==0.8.0\n",
      "wasabi==0.8.0\n",
      "wcwidth==0.2.5\n",
      "webencodings==0.5.1\n",
      "Werkzeug==1.0.1\n",
      "widgetsnbextension==3.5.1\n",
      "wordcloud==1.5.0\n",
      "wrapt==1.12.1\n",
      "xarray==0.15.1\n",
      "xgboost==0.90\n",
      "xkit==0.0.0\n",
      "xlrd==1.1.0\n",
      "xlwt==1.3.0\n",
      "yellowbrick==0.9.1\n",
      "zict==2.0.0\n",
      "zipp==3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQ3ps2xFQV2w"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U keras-tuner\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "V8b8SYYYQ0aj",
    "outputId": "e207c5cc-f905-45ea-9062-ce71518a2776"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 1s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(img_train, label_train), (img_test, label_test) = fashion_mnist.load_data()\n",
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmNZM7xqc8M5"
   },
   "source": [
    "### Creamos la función que define la topología de red y compila el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-5POMBtCQ59Y"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "def model_builder(hp):\n",
    "  model = Sequential()\n",
    "  model.add(Flatten(input_shape=(28, 28)))\n",
    "  \n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
    "  model.add(Dense(units = hp_units, activation = 'relu'))\n",
    "  model.add(Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer \n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "  \n",
    "  model.compile(optimizer = Adam(learning_rate = hp_learning_rate),\n",
    "                loss = SparseCategoricalCrossentropy(from_logits = True), \n",
    "                metrics = ['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "716ZJhsvdvsI"
   },
   "source": [
    "### Instanciamos el objeto optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybpP9msWQ9Bt"
   },
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'val_accuracy', \n",
    "                     max_epochs = 10,\n",
    "                     factor = 3,\n",
    "                     directory = 'my_dir',\n",
    "                     project_name = 'intro_to_kt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p54zfl5Tdb6Q"
   },
   "source": [
    "### Callback para limpiar las salidas de los entrenamientos al finalizar cada paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__-KD5y4RAeB"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import IPython\n",
    "\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "  def on_train_end(*args, **kwargs):\n",
    "    IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhdnWjTudlwo"
   },
   "source": [
    "### Llevamos a cabo la optimización de hiperparámetros y nos quedamos con el mejor resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "roupZB05RD5U",
    "outputId": "9d995a7a-67c7-42f3-888f-34df84205db0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 73fa856aa862d95824569542a32c889a</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8862000107765198</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/bracket: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/epochs: 10</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 416</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 416 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs = 10, validation_data = (img_test, label_test), callbacks = [ClearTrainingOutput()])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "655MPneNfaey"
   },
   "source": [
    "# MLflow\n",
    "Se trata de una plataforma *open source* para la gestión del ciclo de vida de un modelo de *machine learning*. MLflow ofrece cuatro componentes:\n",
    "- ***MLflow Tracking***: Almacenamiento inteligente y monitorización de experimentos (código, datos, configuración y resultados).\n",
    "- ***MLflow Projects***: Paquete de código que permite reproducir cualquier formato de código en cualquier plataforma de trabajo.\n",
    "- ***MLflow Models***: Puesta en marcha de modelo en producción en diversos entornos de servicios.\n",
    "- ***Model Registry***: Almacena, anota, descubre y gestiona modelos en un repositorio centralizado.\n",
    "\n",
    "Demos un paseo por la documentación y ejemplos de la librería: https://mlflow.org/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "DB36wZd_tf-v",
    "y-AG85ARE2rc",
    "bcNbPlTkO8gm"
   ],
   "name": "07MAIR_VC07_Más allá_Colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
