{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bfa170-5c9a-4b72-aa94-868f7ef264ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4afc0-3cd0-46a1-a767-42e41ac94082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv() # Visualizar dataset previo importar para pasar los parámetros correctos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e375f93-9e1d-4672-bc0c-ce6f573baa33",
   "metadata": {},
   "source": [
    "## Ejercicio Normalización\n",
    "\n",
    "Se les brinda un dataset con 500 valores (`outliers.csv`) que deben ser preprocesados previo entrar en la etapa de modelado de datos.\n",
    "\n",
    "- Realizar un split de datos del 80/20. Pueden realizar el split utilizando una función desarrollada por ustedes, o en cuyo caso, utilizar la librería `from sklearn.model_selection import train_test_split` Para mayor información de como utilizarla [Tran Test Split sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Seleccionar `h` como atributo label/target\n",
    "\n",
    "- Aplicar el proceso de normalización\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488fddf-6c9b-4e08-96bc-986899e8c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29cbaaa-ec6e-471c-8804-de29c3c079fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split manual\n",
    "df_train = \n",
    "df_test = \n",
    "X_train = \n",
    "X_test = \n",
    "display (X_train)\n",
    "display (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ab981-c624-49c9-852c-c38605db02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de datos: normalización.\n",
    "normalizer = \n",
    "X_train_norm = \n",
    "print(X_train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c78fe-3ee7-46af-ad00-5582d62b4435",
   "metadata": {},
   "source": [
    "## Ejercicio Estandarización\n",
    "\n",
    "Se les brinda un dataset con 500 valores (`outliers.csv`) que deben ser preprocesados previo entrar en la etapa de modelado de datos.\n",
    "\n",
    "- Realizar un split de datos del 80/20. Pueden realizar el split utilizando una función desarrollada por ustedes, o en cuyo caso, utilizar la librería `from sklearn.model_selection import train_test_split` Para mayor información de como utilizarla [Tran Test Split sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Seleccionar `h` como atributo label/target\n",
    "\n",
    "- Aplicar el proceso de estandarización\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca528a26-a285-4285-a7e4-c378e1bba4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e4b94d-5941-4c35-a0c1-c1246648a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split manual\n",
    "df_train = \n",
    "df_test = \n",
    "X_train = \n",
    "X_test = \n",
    "display (X_train)\n",
    "display (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d88f670-82e2-4407-95c3-7728dd5eac73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Limpieza de datos: estandarización.\n",
    "standardizer = \n",
    "X_train_std = \n",
    "print(X_train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e76f431-a737-4fcc-9929-1e2933ef6bed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ejercicio \n",
    "\n",
    "Se les brinda un dataset de las estadísticas de youtube del año 2023 (`global_youtube_statistics.csv`) que deben ser preprocesados previo entrar en la etapa de modelado de datos.\n",
    "\n",
    "- Crear un nuevo dataframe con los siguientes atributos `suscribers`, `video views`, `uploads`, `created_year`, `channel_type` \n",
    "- Realizar un split de datos del 80/20. Pueden realizar el split utilizando una función desarrollada por ustedes, o en cuyo caso, utilizar la librería `from sklearn.model_selection import train_test_split` Para mayor información de como utilizarla [Tran Test Split sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Seleccionar `channel_type`  como atributo label/target\n",
    "- Aplicar el método de preprocesamiento que considere apropiado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5c5fd-fdb0-45fc-971e-d31e689371e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('global_youtube_statistics.csv', sep=';', encoding='unicode_escape')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c393ef-e8c1-4c3d-a274-324db8db070c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d0a6fd-aa36-4352-bf93-857de1ceafe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_2[[]], \n",
    "                                                    df_2[], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "print(\"Display Train/Test data\")\n",
    "print(\"-----------------------------\")\n",
    "display (X_train.head())\n",
    "print(\"-----------------------------\")\n",
    "display (X_test.head())\n",
    "print(\"-----------------------------\")\n",
    "display (y_train.head())\n",
    "print(\"-----------------------------\")\n",
    "display (y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87134ff8-1953-49b2-8399-a3de1b38761e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer =  #Normalización - Instanciamos normalizador\n",
    "X_train_norm =  #Al normalizador le aplico el método fit_transform para poder normalizar los datos\n",
    "print(X_train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3767a753-e58c-433a-8c93-4fd8bf4a7721",
   "metadata": {},
   "source": [
    "## Ejercicio outliers \n",
    "\n",
    "Se les brinda un dataset con 500 valores (`outliers.csv`) que deben ser preprocesados previo entrar en la etapa de modelado de datos.\n",
    "\n",
    "- Realizar un split de datos del 80/20. Pueden realizar el split utilizando una función desarrollada por ustedes, o en cuyo caso, utilizar la librería `from sklearn.model_selection import train_test_split` Para mayor información de como utilizarla [Tran Test Split sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Seleccionar `h` como atributo label/target\n",
    "\n",
    "- Identificar los posibles outliers usando los algoritmos de `EllipticEnvelope`, `OneClassSVM`, y utilizando el método `IQR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5bc9d0-6065-42dd-91b9-78282411bd79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "from numpy import quantile, where, random\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv() # Visualizar dataset previo importar para pasar los parámetros correctos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00607281-5c11-4c29-bf77-6c784bc3dd8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EllipticEnvelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f12e451-a62f-491c-9a1e-a9c5b5305d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EllipticEnvelope\n",
    "algorithm = EllipticEnvelope() \n",
    "\n",
    "outlier_method = algorithm.fit(X_train)\n",
    "# Aplicamos el método de detección de outliers entrenado sobre nuesto dataset\n",
    "df_outliers = outlier_method.predict(X_train)\n",
    "print(df_outliers)\n",
    "\n",
    "# Determinar la posición de los outliers\n",
    "pos_outliers = np.where()[0] #TODO Completar los parámetros de la función where\n",
    "\n",
    "\n",
    "print('\\nOutliers en la posición: \\n', pos_outliers)\n",
    "\n",
    "# Determinar el número de outliers\n",
    "print('\\nNúmero de outliers: \\n', len(pos_outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9e1b9-4dcb-4c5e-97a5-f31040658308",
   "metadata": {},
   "source": [
    "### OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce1c5e-d52e-4fec-8f60-629cbde5b84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OneClassSVM\n",
    "svm = OneClassSVM()\n",
    "print(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec665d7-2d7b-4136-876c-5e5e65777f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm.fit()\n",
    "df_outliers = svm.predict()\n",
    "print(df_outliers)\n",
    "\n",
    "# Determinar la posición de los outliers\n",
    "pos_outliers = np.where()[0] #TODO Completar los parámetros de la función where\n",
    "\n",
    "print('\\nOutliers en la posición: \\n', pos_outliers)\n",
    "\n",
    "# Determinar el número de outliers\n",
    "print('\\nNúmero de outliers: \\n', len(pos_outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4790654f-6b22-45fa-a7bb-3e081a6c6088",
   "metadata": {},
   "source": [
    "### IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad687a-6364-471b-be83-b9bc74eb3353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_limits_BP(df):\n",
    "    # Seleccionamos el atributo que vamos a medir\n",
    "    b = df\n",
    "\n",
    "    # Seleccionamos los umbrales a partir de los cuales vamos a considerar outliers\n",
    "    Q1 = \n",
    "    Q3 = \n",
    "    RIC = \n",
    "    li = \n",
    "    ls = \n",
    "\n",
    "    # Observamos los límites inferior y superior\n",
    "    print('limite inferior: ', li)\n",
    "    print('limite superior: ', ls)\n",
    "\n",
    "    # Buscamos la posición de los outliers\n",
    "    pos_i = \n",
    "    pos_s = \n",
    "    pos_outliers = np.concatenate((pos_i, pos_s))\n",
    "    print('Posición de outliers: ', pos_outliers)\n",
    "    print('Número de outliers: ', len(pos_outliers))\n",
    "\n",
    "    # Dibujamos el diagrama de caja y bigotes\n",
    "    prop = plt.boxplot(b)\n",
    "    plt.boxplot(b)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50aabf5-c873-4cff-a705-6b85715118fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "find_limits_BP(df_2[[]]) #Tener en cuenta los atributos numéricos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
