{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWoPVl2NohJ4"
      },
      "source": [
        "# Normalización\n",
        "\n",
        "La normalización de un conjunto de datos consiste en transformar los valores de sus atributos numéricos al rango continuo `[0, 1]` mediante una operación matemática llamada `homotecia`. Esta transformación se lleva  a cabo para cada columna (atributo) de forma independiente.\n",
        "Nótese que la normalización hace que a cada valor de un atributo se le reste el mínimo de dicho atributo (columna) y se divida por la diferencia entre máximo y mínimo. La operación de resta se denomina `centrado`, mientras que la división se denomina `escalado`. Por tanto, diremos que la normalización, al igual que otras transformaciones como la estandarización (que veremos a continuación), centra y escala los datos.\n",
        "`La normalización es una transformación muy recomendable cuando se pretenden usar cálculos de distancias o productos escalares entre ejemplos`. En caso de no aplicar normalización, la diferencia de escalas de valores entre los atributos puede hacer que uno tenga más influencia que otro.\n",
        "\n",
        ">Note: Para ello se toma el mínimo y se lo divide por la diferencia entre el max y el min."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [],
        "id": "PsnqutXQohJ-"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "71Io3GlAohKB",
        "outputId": "91f52bfa-ed96-46f9-8af2-590648559c01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[   4., -200.,    2.],\n",
              "       [   5.,    4.,    6.],\n",
              "       [   3.,    1.,   -8.]])"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Carga de datos.\n",
        "X_train = np.array([[ 4., -200.,  2.],\n",
        "                    [ 5.,  4.,  6.],\n",
        "                    [ 3.,  1., -8.]])\n",
        "\n",
        "display(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "id": "4wyTzQU4ohKE"
      },
      "outputs": [],
      "source": [
        "# Limpieza de datos: normalización.\n",
        "normalizer = preprocessing.MinMaxScaler() #Normalización - Instanciamos normalizador\n",
        "X_train_norm = normalizer.fit_transform(X_train) #Al normalizador le aplico el método fit_transform para poder normalizar los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NznGiT1nohKG",
        "outputId": "39116ab4-2988-4445-b247-88d2698795bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5        0.         0.71428571]\n",
            " [1.         1.         1.        ]\n",
            " [0.         0.98529412 0.        ]]\n"
          ]
        }
      ],
      "source": [
        "# Salida de resultados.\n",
        "print(X_train_norm) #Aquí podemos observar como pone todos los valores entre 0 y 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Crear el objeto MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Aplicar la función fit al objeto scaler\n",
        "scaler.fit(X_train_2)\n",
        "\n",
        "# Aplicar la función transform al objeto X_train_2\n",
        "X_train_norm_2 = scaler.transform(X_train_2)\n",
        "\n",
        "# Comprueba si \"X_train_norm\" y \"X_train_norm_2\" son iguales\n",
        "print(np.array_equiv(X_train_norm, X_train_norm_2))\n",
        "print(X_train_norm_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm-c0eB1sFDl",
        "outputId": "7850a9a7-fd02-443e-aebc-50cbb95cedea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "[[0.5        0.         0.71428571]\n",
            " [1.         1.         1.        ]\n",
            " [0.         0.98529412 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhVfPuplohKI"
      },
      "source": [
        "## Datos de test\n",
        "\n",
        "Normalizar los datos de `X_test`???\n",
        "\n",
        "En este caso, para los datos de test solo hay que transformar, no utilizar el fit. Es error grave de interpretación y afecta el experimento.\n",
        "\n",
        "Si usa `fit_transform()` con el conjunto de datos de prueba, básicamente ajustaría su modelo/escalador para aprender también de los datos de prueba, lo que provoca una fuga de datos. Recuerde, se supone que el conjunto de datos de prueba es un conjunto de datos invisible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uyk0-LbuohKJ",
        "outputId": "c6eff803-9986-401d-efc2-27d20d20180e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.          0.8627451   0.71428571]\n",
            " [ 0.5         0.98039216  0.57142857]\n",
            " [-1.5         0.98529412  0.5       ]]\n"
          ]
        }
      ],
      "source": [
        "# Normalizar un nuevo conjunto de datos de test (SOLO HAY QUE APLICAR EL MÉTODO \"transform\", NO EL \"fit\")\n",
        "X_test = np.array([[ 1., -24.,  2.],\n",
        "                    [ 4.,  0.,  0.],\n",
        "                    [ 0.,  1., -1.]])\n",
        "\n",
        "# Normalizar los datos de \"X_test\"\n",
        "# Aplicar la función transform al objeto X_test\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "#X_test_norm = fitted_normalizer.transform(X_test)\n",
        "print(X_test_norm)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}