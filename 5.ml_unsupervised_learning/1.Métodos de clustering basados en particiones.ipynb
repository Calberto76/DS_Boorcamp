{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSxsktEaLU84"
   },
   "source": [
    "# Métodos de clustering basados en particiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9u-RUfTUbLe5"
   },
   "source": [
    "Vamos a ver algunos ejemplos de clustering con K-means.\n",
    "\n",
    "En el primer ejemplo, vamos a intentar clusterizar un dataset de números. Este dataset consiste en 1797 imágenes (ejemplos/instancias) con 64 atributos (características/variables/*features*), donde cada una de esos 64 atributos es la intensidad de un pixel de una imagen en escala de grises de 8x8:\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_digits_classification_001.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1663265214725,
     "user": {
      "displayName": "juan de la rosa",
      "userId": "00154642105492654987"
     },
     "user_tz": 300
    },
    "id": "DP2-10tRbaX8",
    "outputId": "6563cf75-424f-4747-fecf-5231682966d6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 8]\n",
    "digits = load_digits()\n",
    "digits.data.shape # la dimensión es instancias por caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JE0IW8aEDMvA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(digits.data[1000].reshape((8,8)),cmap='gray') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_rxKiUcbcwb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utilizamos k-means para hacer el clustering\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=0)\n",
    "clusters=kmeans.fit_predict(digits.data)\n",
    "kmeans.cluster_centers_.shape #Accedo al shape de los centroides\n",
    "clusters.shape #shape de C, arreglo de 1xN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M7ISy8Gbu_-"
   },
   "source": [
    "Fijaos que el resultado del clustering son 10 centroides (1 por cada cluster que le hemos pedido). Además, como hemos utilizado los pixeles \"en crudo\", estos centroides tienen las mismas dimensiones que las imágenes de entrada (`10x64`) y representan al \"típico\" número de cada cluster. Vamos a visualizarlos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bbUcIGQbgAu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 5, figsize=(8, 3))\n",
    "centers = kmeans.cluster_centers_.reshape(10, 8, 8)\n",
    "for axi, center in zip(ax.flat, centers):\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.imshow(center, interpolation='nearest', cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaigRvhkcWWu"
   },
   "source": [
    "Tal y como podemos observar, el K-means es capaz de encontrar los clusters cuyos centros son los números del 0 al 9, a excepción del 1 y el 8 que los confunde un poco.\n",
    "\n",
    "Vamos a calcular algunas métricas intrínsecas y extrínsecas de las vistas en clase para comprobar cómo ha ido el clustering cuantitativamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rlbJ0ANEpfc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXp-V1nobkJU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Completness score =', cluster.completeness_score(digits.target, clusters)) ## Aquí tu código ##(digits.target, clusters))\n",
    "print('Homogeneidad =', cluster.homogeneity_score(digits.target, clusters))\n",
    "print('Información mutua (ajustada) =', cluster.homogeneity_score(digits.target, clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TbvFN0mduWS"
   },
   "source": [
    "Ya que tenemos las etiquetas reales, vamos a calcular el accuracy. Para ello, vamos a usar la función `accuracy_score` disponible en  `sklearn.metrics`.\n",
    "\n",
    "Daos cuenta de que como hemos hablado en las clases, el k-means hace agrupamientos pero no tiene ni idea de a qué *clase* pertenece cada uno. Simplemente agrupa las imágenes por similitud, de forma parecida a lo que haría un *k nearest neighbours (kNN)* o algoritmo de vecinos cercanos.\n",
    "\n",
    "Por ello, lo primero que vamos a hacer es asignarle a cada cluster la etiqueta de acuerdo a la moda de sus elementos. Es decir, nos fijaremos en qué elemento se repite más en cada cluster, y ese será la etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mV1Y3MTlfDww",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(10):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(digits.target[mask])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYcJDD1XfJNK"
   },
   "source": [
    "Y ahora ya podemos calcular el accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMSL_-HdfEGj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(digits.target, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAGfRs8DfPxM"
   },
   "source": [
    "Y también la matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVkB2AW_fLa_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(digits.target, labels)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=digits.target_names,\n",
    "            yticklabels=digits.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6nBJssCfln4"
   },
   "source": [
    "Fijaos que hemos conseguido clasificar correctamente el 80% de nuestras imágenes con un simple K-means sin siquiera preprocesar los datos. Como hemos comprobado antes al plotear las imágenes, el algoritmo se confunde sobretodo con el 1 y el 8.\n",
    "\n",
    "¿Y si realizásemos algún tipo de preprocesamiento que nos permitiese mejorar los resultados?\n",
    "\n",
    "Vamos a ver qué pasaría si usásemos una técnica de reducción de dimensionalidad conocida como t-SNE (https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMNSzTJrGDWO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE #TSNE parecido a PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVRF1sLrgnGu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utilizamos t-SNE para proyectar los datos en otro espacio de 2 dimensiones\n",
    "# Este paso tarda unos segundos, no os impacientéis :)\n",
    "## Se puede utilizar GridSearchCV para poder encontrar\n",
    "## el K y el n_components en TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, init='random', random_state=42)\n",
    "digits_proj = tsne.fit_transform(digits.data)\n",
    "\n",
    "# Realizamos el clustering\n",
    "## Aquí tu código ##\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "clusters = kmeans.fit_predict(digits_proj)\n",
    "\n",
    "# Asignamos las etiquetas de acuerdo a la moda\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(10):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(digits.target[mask])[0]\n",
    "\n",
    "# Calculamos el accuracy\n",
    "accuracy_score(digits.target, labels)\n",
    "\n",
    "# Mostramos la matriz de confusión\n",
    "## Aquí tu código ##\n",
    "mat = confusion_matrix(digits.target,labels)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=digits.target_names,\n",
    "            yticklabels=digits.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVGHX5hOWOQw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_score(digits.target, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKRnuMZUhB4m"
   },
   "source": [
    "¿Qué os parece? Daos cuenta de la importancia de preprocesar los datos de una forma adecuada. Con esta simple decisión hemos mejorado en un 13% la precisión de nuestro algoritmo.\n",
    "\n",
    "¡Que no se os olvide! ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTsW7C0whTJE"
   },
   "source": [
    "El segundo ejemplo que vamos a ver trata sobre compresión de imágenes. Sí, aunque parezca mentira, se pueden usar técnicas de clustering para ello.\n",
    "\n",
    "Simplemente reducimos el número total de colores utilizados para representar la imagen, y de esta forma permitimos que se necesiten menos memoria (bits) para su almacenaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-I90U6Fhpa8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_image\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "ax = plt.axes(xticks=[], yticks=[])\n",
    "ax.imshow(china);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4NRkLUGh1Dn"
   },
   "source": [
    "Recordad que las imagenes se representan como matrices de `(alto, ancho, canales)`, donde los valores de los canales son rojo/verde/azul y varían de 0 a 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXRzMGkjhpyP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "china.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzLuN4TdiIAT"
   },
   "source": [
    "Sin embargo, podemos ver este dataset como una nube de puntos tridimensional, donde cada pixel es una instancia.\n",
    "\n",
    "Vamos a normalizar los valores entre 0 y 1 y a convertirlos en `[n_instancias, 3]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHpi3xezXWrL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "china.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GiCZqMKziG02",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalizamos la imagen para que tenga valores entre 0 y 1\n",
    "data = china / 255 \n",
    "data = data.reshape(427 * 640, 3)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWGCP0fLiZXU"
   },
   "source": [
    "Ahora vamos a visualizar los pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91vVxe08iV8z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_pixels(data, title, colors=None, N=10000):\n",
    "    if colors is None:\n",
    "        colors = data\n",
    "    \n",
    "    # choose a random subset\n",
    "    rng = np.random.RandomState(0)\n",
    "    i = rng.permutation(data.shape[0])[:N]\n",
    "    colors = colors[i]\n",
    "    R, G, B = data[i].T\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    ax[0].scatter(R, G, color=colors, marker='.')\n",
    "    ax[0].set(xlabel='Red', ylabel='Green', xlim=(0, 1), ylim=(0, 1))\n",
    "\n",
    "    ax[1].scatter(R, B, color=colors, marker='.')\n",
    "    ax[1].set(xlabel='Red', ylabel='Blue', xlim=(0, 1), ylim=(0, 1))\n",
    "\n",
    "    fig.suptitle(title, size=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPrqNB7YidHK"
   },
   "outputs": [],
   "source": [
    "plot_pixels(data, title='Input color space: 16 million possible colors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4n2gCd8ilc2"
   },
   "source": [
    "Vamos ahora a reducir de 16 millones de colores a 16.\n",
    "\n",
    "Como se trata de un dataset grande, vamos a usar una variación del k-means llamada mini-batch k-Means, que funciona exactamente igual que el k-means pero con mini-batches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRSxsW_Eidfu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')  # Fix NumPy issues.\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "kmeans = MiniBatchKMeans(16)\n",
    "kmeans.fit(data)\n",
    "new_colors = kmeans.cluster_centers_[kmeans.predict(data)]\n",
    "\n",
    "plot_pixels(data, colors=new_colors, title=\"Reduced color space: 16 colors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXFCdCVci9KO"
   },
   "source": [
    "Perfecto. Acabamos de conseguir reducir el número de colores a 16, como podéis observar.\n",
    "\n",
    "Vamos a transformar la imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXoY0n-KjDuo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "china_recolored = new_colors.reshape(china.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6), subplot_kw=dict(xticks=[], yticks=[]))\n",
    "fig.subplots_adjust(wspace=0.05)\n",
    "ax[0].imshow(china)\n",
    "ax[0].set_title('Original Image', size=16)\n",
    "ax[1].imshow(china_recolored)\n",
    "ax[1].set_title('16-color Image', size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "china_recolored.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bZrns7njJRN"
   },
   "source": [
    "Es indiscutible que se pierde calidad, pero pensad que acabamos de conseguir comprimir la imagen con un factor de más o menos 1 millón!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHEohCy9jbBV"
   },
   "source": [
    "La fuente de estos ejemplos, para quien quiera consultarla: \n",
    "\n",
    "*   https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html\n",
    "*   https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html\n",
    "*   https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMclnPyTjdX4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(china_recolored.shape)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
