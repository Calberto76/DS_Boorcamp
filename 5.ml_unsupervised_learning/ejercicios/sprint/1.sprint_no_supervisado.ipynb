{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eb179ae-7ec9-4edb-a38b-77910514e57e",
   "metadata": {
    "id": "4eb179ae-7ec9-4edb-a38b-77910514e57e"
   },
   "source": [
    "# Sprint\n",
    "\n",
    "La siguiente entrega tiene como objetivo poder evaluar los conocimientos adquiridos durante el transcurso del módulo de **Aprendizaje no supervisado**.\n",
    "\n",
    "Para ello evaluaremos dos aspectos principales:\n",
    "\n",
    "- Conocimientos fundamentales sobre agrupamiento, redes generativas, y autoencoders\n",
    "- Ejercicios que permitan evaluar la implementación de código\n",
    "\n",
    ">Note: Aquellos ejercicios teóricos, mantener la respuesta en formato Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa087dd1-b092-440b-ae3d-3a49626df4e5",
   "metadata": {
    "id": "aa087dd1-b092-440b-ae3d-3a49626df4e5"
   },
   "source": [
    "# Ejercicio 1 (Teoría)\n",
    "Responda brevente a los siguientes puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32a4f1d-0174-443a-a933-5ed769aed149",
   "metadata": {
    "id": "d32a4f1d-0174-443a-a933-5ed769aed149"
   },
   "source": [
    "1. Defina en sus propios términos la `Dispersión Intraclúster`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d785bd7-83fe-4ea7-9c99-51d21ba98e02",
   "metadata": {
    "id": "1d785bd7-83fe-4ea7-9c99-51d21ba98e02"
   },
   "source": [
    "2. En agrupamiento jerárquico, qué buscamos con la `Disimilitud máxima`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cfde4b-c368-40e0-8737-bf7218a35c52",
   "metadata": {
    "id": "46cfde4b-c368-40e0-8737-bf7218a35c52"
   },
   "source": [
    "3. Defina los pasos para obtener un `Agrupamiento Espectral`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6c982-1097-4510-809c-aa9ab74f00ef",
   "metadata": {
    "id": "17b6c982-1097-4510-809c-aa9ab74f00ef"
   },
   "source": [
    "4. `PCA` se considera un algoritmo supervisado o no supervisado?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a1deca-cc7b-4fb7-8c6b-946377114974",
   "metadata": {
    "id": "33a1deca-cc7b-4fb7-8c6b-946377114974"
   },
   "source": [
    "5. Cuál es el principal uso del análisis de componentes (`PCA`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33733e2b-eeeb-4cbe-807b-b932999d6b80",
   "metadata": {
    "id": "33733e2b-eeeb-4cbe-807b-b932999d6b80"
   },
   "source": [
    "6. Cómo se entrena una `GAN`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b735945-f3e1-48aa-9564-b2fc5678db53",
   "metadata": {
    "id": "6b735945-f3e1-48aa-9564-b2fc5678db53",
    "tags": []
   },
   "source": [
    "7. Cómo funciona un `Auto Encoder`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6c5d4c-0da8-4935-8ab6-1502578490ba",
   "metadata": {
    "id": "7d6c5d4c-0da8-4935-8ab6-1502578490ba"
   },
   "source": [
    "8. Cómo funciona un `Varational Auto Encoder`? Explique la principal diferencia con un `Auto Encoder`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd48bbf0-42c9-4fc9-87c4-906b7bdc0c7f",
   "metadata": {
    "id": "cd48bbf0-42c9-4fc9-87c4-906b7bdc0c7f"
   },
   "source": [
    "# Ejercicio 2\n",
    "Importar una imágen, ya sea del dataset de `skimage` o de tu preferencia y realizar segementación utilizando grafos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd2cd8-4853-4486-a414-3f1bddd1d997",
   "metadata": {
    "id": "8fdd2cd8-4853-4486-a414-3f1bddd1d997"
   },
   "outputs": [],
   "source": [
    "from skimage import data, segmentation, color\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c45226-7c80-40b0-a93f-e47aa3fa7df4",
   "metadata": {
    "id": "06c45226-7c80-40b0-a93f-e47aa3fa7df4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d24bb-aedf-4c6a-95c7-a3b0df81090a",
   "metadata": {
    "id": "6d6d24bb-aedf-4c6a-95c7-a3b0df81090a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5141c9e0-7968-4964-a5ef-cc98c694e389",
   "metadata": {
    "id": "5141c9e0-7968-4964-a5ef-cc98c694e389"
   },
   "source": [
    "# Ejercicio 3\n",
    "\n",
    "Utilizando la misma imagen del `Ejercicio 2`, realizar una segementación mediante otro método conocido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080c939-c266-4273-b7da-cfd9b21efd28",
   "metadata": {
    "id": "4080c939-c266-4273-b7da-cfd9b21efd28"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6a3a34-0aef-41f1-9ec3-685841000ac0",
   "metadata": {
    "id": "4d6a3a34-0aef-41f1-9ec3-685841000ac0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "777a8d51-024d-4c6f-abff-3674ae4928f9",
   "metadata": {
    "id": "777a8d51-024d-4c6f-abff-3674ae4928f9"
   },
   "source": [
    "# Ejercicio 4\n",
    "Utilizando el dataset de dígitos del `Mnist` realizar una reducción de dimensionalidad utilizando algún método conocido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10bfd0d-0ada-4511-9862-b79477682fbc",
   "metadata": {
    "id": "b10bfd0d-0ada-4511-9862-b79477682fbc"
   },
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_digits as LoadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e1208-9f51-4ed0-93e9-8f04e2591b67",
   "metadata": {
    "id": "da7e1208-9f51-4ed0-93e9-8f04e2591b67"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807347a9-95ef-43b4-b9fc-a54e72ed05f7",
   "metadata": {
    "id": "807347a9-95ef-43b4-b9fc-a54e72ed05f7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86c764c3-757d-41c6-90d1-99aaac4dfc1e",
   "metadata": {
    "id": "86c764c3-757d-41c6-90d1-99aaac4dfc1e",
    "tags": []
   },
   "source": [
    "# Ejercicio 5 (Teoría)\n",
    "Cuál es el objetivo de la siguiente clase y en que tipo de arquitectura/algoritmo se ve implementado. Qué debe retornar como resultado y cúal es el significado de ese valor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1066cac5-f80b-4a86-bc70-fd309b2d6a6f",
   "metadata": {
    "id": "1066cac5-f80b-4a86-bc70-fd309b2d6a6f"
   },
   "outputs": [],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "  def call(self, inputs):\n",
    "    mu, sigma = inputs\n",
    "    batch = tf.shape(mu)[0]\n",
    "    dim = tf.shape(mu)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape = (batch, dim))\n",
    "    z = mu + tf.exp(0.5 * sigma) * epsilon\n",
    "    return  # TODO Qué debe devolver?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7921d-d82f-4f23-ac72-937a29d42acd",
   "metadata": {
    "id": "bed7921d-d82f-4f23-ac72-937a29d42acd"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d29505f4-15c0-47c3-8b51-0a06b6b2f257",
   "metadata": {
    "id": "d29505f4-15c0-47c3-8b51-0a06b6b2f257"
   },
   "source": [
    "# Ejercicio 6 (COLAB)\n",
    "\n",
    "Implemente una `GAN` para el siguiente dataset:\n",
    "\n",
    "[Link de descarga]()\n",
    "\n",
    ">Note: (15, 15) Es el tamaño de cada imágen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55173c79-7da2-413b-a16e-24ef7d0280b0",
   "metadata": {
    "id": "55173c79-7da2-413b-a16e-24ef7d0280b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for mathematical operations\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# for image related operations\n",
    "import PIL\n",
    "# for warnings\n",
    "import zipfile\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from PIL import Image\n",
    "import tensorflow  as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, UpSampling2D, Conv2D, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU, Dropout, ZeroPadding2D, Flatten, Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Rzze7YVGe7PS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rzze7YVGe7PS",
    "outputId": "0884d882-f820-4b38-9c66-8f7c0b831583"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572257fd-879b-498e-9a49-1403569ee254",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "572257fd-879b-498e-9a49-1403569ee254",
    "outputId": "2dccd50d-c8db-4eab-b66d-b164d90311d3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing data\n",
    "data_path = \"\" # Utilizar el path correspondiente\n",
    "batch_size = 64 # can use 32 or 128 as well\n",
    "\n",
    "# tf.keras.preprocessing.image_dataset_from_directory generates a tf.data.Dataset from image files in a directory\n",
    "data = tf.keras.preprocessing.image_dataset_from_directory(data_path,\n",
    "                                                           label_mode = None,\n",
    "                                                           image_size = (64,64),\n",
    "                                                           batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b674b3e-6590-48c1-9697-df77a70a217a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2b674b3e-6590-48c1-9697-df77a70a217a",
    "outputId": "9cd98400-c919-4a9f-f168-62ed5f9b170d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15)) # (15, 15) is the size of each image\n",
    "for images in data.take(1):\n",
    "    for i in range(30): # display 30 images\n",
    "        ax = plt.subplot(6, 5, i + 1) # 6 rows, 5 columns for the i+1th image (i starts from 0 hence 1 is added)\n",
    "\n",
    "        # dataset needs to be first converted to numpy array to be displayed. unit8 has range from 0 to 255 which fits perfectly for our image data, hence this is used\n",
    "        ax.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        ax.axis(\"off\") # turns off the pixel indicator axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d4327-4898-47e6-a124-dfc334e1ef93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea4d4327-4898-47e6-a124-dfc334e1ef93",
    "outputId": "cc657eb3-4372-4616-ed92-d843bc81312d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "# building a generator\n",
    "generator = Sequential()\n",
    "generator.add(Dense(4*4*256, activation=, input_dim=)) #TODO\n",
    "generator.add(Reshape((4,4,256)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Activation()) #TODO\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Activation()) #TODO\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(256,kernel_size=3,padding=\"same\"))#\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Activation()) #TODO\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Activation()) #TODO\n",
    "generator.add(Conv2D(3,kernel_size=3,padding=\"same\"))\n",
    "generator.add(Activation(\"tanh\"))\n",
    "\n",
    "generator.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec6eae4-0dcf-44f2-8b9d-6628b1294acc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ec6eae4-0dcf-44f2-8b9d-6628b1294acc",
    "outputId": "1ad5cc80-5efe-4720-da55-8883834517d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# building the discriminator\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(32, kernel_size=3, strides=2, input_shape=(64,64,3), padding=\"same\"))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.25))\n",
    "discriminator.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "discriminator.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "discriminator.add(BatchNormalization(momentum=0.8))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.25)) # can experiment by removing Dropout layer. I got better performance with it hence using it\n",
    "discriminator.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "discriminator.add(BatchNormalization(momentum=0.8))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.25))\n",
    "discriminator.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "discriminator.add(BatchNormalization(momentum=0.8))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.25))\n",
    "discriminator.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "discriminator.add(BatchNormalization(momentum=0.8))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.25))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation=\"\")) #TODO\n",
    "\n",
    "discriminator.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792bd81b-c5c7-40b5-be75-4fa2110842b2",
   "metadata": {
    "id": "792bd81b-c5c7-40b5-be75-4fa2110842b2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GAN(tf.keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        # decode them to fake images\n",
    "        generated_images = self.generator(noise)\n",
    "        # combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "        # assemble labels discriminating real from fake images\n",
    "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
    "        # add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "        # train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        # sample random points in the latent space\n",
    "        noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # train the generator (note that we should *not* update the weights of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(noise))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\"d_loss\": self.d_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UdlDGf57iMbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UdlDGf57iMbf",
    "outputId": "eedd9f8f-40b2-4e5a-898f-399f984b427d"
   },
   "outputs": [],
   "source": [
    "# defining the number of epochs\n",
    "epochs = #TODO\n",
    "\n",
    "# the optimizers for generator and discriminator\n",
    "discriminator_opt = tf.keras.optimizers.Adamax(1.5e-4,0.5)\n",
    "generator_opt = tf.keras.optimizers.Adamax(1.5e-4,0.5)\n",
    "\n",
    "# to compute cross entropy loss\n",
    "loss_fn = #TODO\n",
    "\n",
    "# defining GAN model\n",
    "model = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "\n",
    "# compiling GAN model\n",
    "model.compile(d_optimizer=discriminator_opt, g_optimizer=generator_opt, loss_fn=loss_fn)\n",
    "\n",
    "# fitting the GAN\n",
    "history = model.fit() #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8173ec23-33b4-475f-ad85-f2ded1e9b50b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "8173ec23-33b4-475f-ad85-f2ded1e9b50b",
    "outputId": "38a9baa6-0212-402f-b2fe-366a593cfd53"
   },
   "outputs": [],
   "source": [
    "# number of images to be generated\n",
    "num_img=30\n",
    "\n",
    "# a function to generate and save images\n",
    "def Image_Generator():\n",
    "    Generated_images = []\n",
    "    noise = tf.random.normal([num_img, latent_dim])\n",
    "    generated_image = generator(noise)\n",
    "    generated_image *= 255\n",
    "    generated_image = generated_image.numpy()\n",
    "    for i in range(num_img):\n",
    "            img = tf.keras.preprocessing.image.array_to_img(generated_image[i])\n",
    "            Generated_images.append(img)\n",
    "            img.save(\"image{:02d}.png\".format(i))\n",
    "    return\n",
    "\n",
    "# generating images\n",
    "Images = Image_Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c45f7e-7a18-45e0-bee7-ca508d0e6c63",
   "metadata": {
    "id": "04c45f7e-7a18-45e0-bee7-ca508d0e6c63"
   },
   "outputs": [],
   "source": [
    "Generated_path = \"\" #TODO\n",
    "Images_generated = tf.keras.preprocessing.image_dataset_from_directory(Generated_path, label_mode = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0855c6f1-6444-444e-8911-68b44f2ec943",
   "metadata": {
    "id": "0855c6f1-6444-444e-8911-68b44f2ec943"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for images in Images_generated.take(1):\n",
    "    for i in range(30):\n",
    "        ax = plt.subplot(5, 6, i + 1)\n",
    "        ax.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        ax.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
