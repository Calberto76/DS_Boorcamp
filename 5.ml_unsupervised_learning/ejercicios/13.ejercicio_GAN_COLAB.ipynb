{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c907d7de-aa87-4e3c-8656-a1168946753e",
   "metadata": {
    "id": "c907d7de-aa87-4e3c-8656-a1168946753e"
   },
   "source": [
    "# Ejercicio 1 - GAN MNIST Dataset\n",
    "\n",
    "Para el siguiente ejemplo, utilizaremos el dataset de fashion MNIST que contiene imagenes de 28x28 pixeles de diferentes artículos.\n",
    "\n",
    "Implementaremos un Generador y un Discriminador y observaremos los resultados luego de ejectuar 100 epochs (puedes variar la cantidad de ciclos para obtener mejores resultados)\n",
    "\n",
    "Se recomienda ejecutar el notebook completo en **COLAB**\n",
    "\n",
    ">Note: Debes importar el archivo `fashion-mnist_train.csv` dentro del directorio `sample_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22077dd6-51d0-4350-bd8b-a9189660e99b",
   "metadata": {
    "id": "22077dd6-51d0-4350-bd8b-a9189660e99b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f431a69-61ff-4fac-9b35-d931fd3d2f73",
   "metadata": {
    "id": "0f431a69-61ff-4fac-9b35-d931fd3d2f73",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,Dropout,Dense,Flatten,Conv2DTranspose,BatchNormalization,LeakyReLU,Reshape\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3595b-69a3-4759-a6bd-bb13647b028f",
   "metadata": {
    "id": "eca3595b-69a3-4759-a6bd-bb13647b028f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = #TODO\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3f836-e85d-437f-b88f-9f2d30e4af19",
   "metadata": {
    "id": "5cc3f836-e85d-437f-b88f-9f2d30e4af19",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = #TODO\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2c09b5-8a04-4666-975b-eaeb5684574c",
   "metadata": {
    "id": "7a2c09b5-8a04-4666-975b-eaeb5684574c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train=X_train.values\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b398f683-43d2-41d9-b399-5d837ae6741e",
   "metadata": {
    "id": "b398f683-43d2-41d9-b399-5d837ae6741e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reshape\n",
    "X_train=#TODO realizar un reshape, recordar la opción -1 y las dimensiones de entrada 28,28,1\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228518d-e096-4fa2-89de-6c3a8a21da62",
   "metadata": {
    "id": "d228518d-e096-4fa2-89de-6c3a8a21da62",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizamos\n",
    "fig,axe=plt.subplots(2,2)\n",
    "idx = 0\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axe[i,j].imshow(X_train[idx].reshape(28,28),cmap='gray')\n",
    "        idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dcade3-eddb-4d2a-a496-b03c30608003",
   "metadata": {
    "id": "46dcade3-eddb-4d2a-a496-b03c30608003",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train =  X_train.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf05119-df57-4c1f-b1e3-e57d6a9f29f0",
   "metadata": {
    "id": "eaf05119-df57-4c1f-b1e3-e57d6a9f29f0"
   },
   "source": [
    "Los datos de píxeles varían de 0 a 255, por lo que se divide cada píxel entre 255, es decir, se normalizan los datos de modo que el rango esté entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e490041-b4e6-4385-be23-67de3b1f52b1",
   "metadata": {
    "id": "2e490041-b4e6-4385-be23-67de3b1f52b1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = #TODO\n",
    "X_train = X_train*2 - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1d1a2-eac2-4373-8e2b-035011f2e925",
   "metadata": {
    "id": "f0f1d1a2-eac2-4373-8e2b-035011f2e925",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generador\n",
    "generator = Sequential()\n",
    "generator.add(Dense(512,input_shape=[100]))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Dense(256))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Dense(128))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Dense(784))\n",
    "generator.add(Reshape([])) #TODO completar con la capa de salida (hint: es el tamaño de la imagen por un canal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1149a62-464e-4d26-a2c6-76d3643920f5",
   "metadata": {
    "id": "f1149a62-464e-4d26-a2c6-76d3643920f5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df217e-9f85-4dc9-ad02-ac8e509baa92",
   "metadata": {
    "id": "04df217e-9f85-4dc9-ad02-ac8e509baa92",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Discriminador\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Dense(1,input_shape=[28,28,1]))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(256))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.5))\n",
    "discriminator.add(Dense(128))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.5))\n",
    "discriminator.add(Dense(64))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.5))\n",
    "discriminator.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb372e9-554c-4a88-9986-069959c3f217",
   "metadata": {
    "id": "0fb372e9-554c-4a88-9986-069959c3f217",
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c26eea-3c74-4810-9285-10ab848c0f72",
   "metadata": {
    "id": "f3c26eea-3c74-4810-9285-10ab848c0f72",
    "tags": []
   },
   "outputs": [],
   "source": [
    "GAN =Sequential([generator,discriminator])\n",
    "discriminator.compile(optimizer=,loss=) #TODO\n",
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c92c7-bfbe-4af0-ba07-a74a37ec40c4",
   "metadata": {
    "id": "324c92c7-bfbe-4af0-ba07-a74a37ec40c4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "GAN.compile(optimizer=,loss=) #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5773d95-1e39-480c-9b8d-bcefd0d26027",
   "metadata": {
    "id": "a5773d95-1e39-480c-9b8d-bcefd0d26027",
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 100\n",
    "noise_shape=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce1ecc9-5539-424b-b534-c74262e0f7ba",
   "metadata": {
    "id": "1ce1ecc9-5539-424b-b534-c74262e0f7ba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    " for epoch in range(epochs):\n",
    "    print(f\"Currently on Epoch {epoch+1}\")\n",
    "\n",
    "\n",
    "    for i in range(X_train.shape[0]//batch_size):\n",
    "\n",
    "        if (i+1)%50 == 0:\n",
    "            print(f\"\\tCurrently on batch number {i+1} of {X_train.shape[0]//batch_size}\")\n",
    "\n",
    "        noise=np.random.normal(size=[batch_size,noise_shape])\n",
    "\n",
    "        gen_image = generator.predict_on_batch(noise)\n",
    "\n",
    "        train_dataset = X_train[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "        #training discriminator on real images\n",
    "        train_label=np.ones(shape=(batch_size,1))\n",
    "        discriminator.trainable = True\n",
    "        d_loss_real=discriminator.train_on_batch(train_dataset,train_label)\n",
    "\n",
    "        #training discriminator on fake images\n",
    "        train_label=np.zeros(shape=(batch_size,1))\n",
    "        d_loss_fake=discriminator.train_on_batch(gen_image,train_label)\n",
    "\n",
    "\n",
    "        #training generator\n",
    "        noise=np.random.normal(size=[batch_size,noise_shape])\n",
    "        train_label=np.ones(shape=(batch_size,1))\n",
    "        discriminator.trainable = False\n",
    "\n",
    "        d_g_loss_batch =GAN.train_on_batch(noise, train_label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #plotting generated images at the start and then after every 10 epoch\n",
    "    if epoch % 10 == 0:\n",
    "        samples = 10\n",
    "        x_fake = generator.predict(np.random.normal(loc=0, scale=1, size=(samples, 100)))\n",
    "\n",
    "        for k in range(samples):\n",
    "            plt.subplot(2, 5, k+1)\n",
    "            plt.imshow(x_fake[k].reshape(28, 28), cmap='gray')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print('Training is complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f888e89f-3dd2-476b-a137-f603645d82f7",
   "metadata": {
    "id": "f888e89f-3dd2-476b-a137-f603645d82f7"
   },
   "outputs": [],
   "source": [
    "noise=np.random.normal(size=[10,noise_shape])\n",
    "gen_image = generator.predict(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fd51b6-8eeb-4a49-ab5f-a3661cad2338",
   "metadata": {
    "id": "45fd51b6-8eeb-4a49-ab5f-a3661cad2338"
   },
   "outputs": [],
   "source": [
    "plt.imshow(noise)\n",
    "plt.title('How the noise looks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69eaa93-4cc8-4d9e-b541-8b607439a160",
   "metadata": {
    "id": "a69eaa93-4cc8-4d9e-b541-8b607439a160"
   },
   "outputs": [],
   "source": [
    "fig,axe=plt.subplots(2,5)\n",
    "fig.suptitle('Generated Images from Noise using GANs')\n",
    "idx=0\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "         axe[i,j].imshow(gen_image[idx].reshape(28,28),cmap='gray')\n",
    "         idx+=10"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
