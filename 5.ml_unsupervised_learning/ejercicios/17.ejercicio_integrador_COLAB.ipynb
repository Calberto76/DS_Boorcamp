{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14564895-253a-4d76-a5b4-9669fa2619b7",
   "metadata": {},
   "source": [
    "# Ejercicio 1 - PCA\n",
    "\n",
    "Tomar el sample dataset de `diabetes` de la librería `sklearn` y realizar la reducción de dimensionalidad correspondiente para obtener la extracción de características `feature extraction`. Describir el proceso y su resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a26b6-cce1-40bc-b490-bba6b5631a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_diabetes\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008c09e-d47f-4fb7-a28c-7b2d1d6212ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = #TODO\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f324db6-43a7-424d-9e43-13e36091d376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca=PCA() #TODO\n",
    "pca.fit() #TODO\n",
    "a,b = #TODO pca.explained_variance_\n",
    "a = a.round(5) # Rendoar valores para poder mostrarlos como título\n",
    "b = b.round(5) # Rendoar valores para poder mostrarlos como título\n",
    "Z=pca.transform(X)\n",
    "plt.title('Explained Variance:' + str(a) + ',' + str(b))\n",
    "plt.axis('equal')\n",
    "plt.scatter(Z[:,0], Z[:,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e387cb-d268-4abf-9258-2b4f914cc1f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng=np.random.RandomState(0)\n",
    "X=rng.randn(3,400)\n",
    "p=rng.rand(10,3)  # Random projection into 10d\n",
    "X=np.dot(p, X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162de5d6-511c-476f-b6a9-b710e1bc1487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca=PCA()\n",
    "pca.fit() #TODO\n",
    "v=#TODO pca.explained_variance_\n",
    "print(v)\n",
    "plt.plot(np.arange(1,11), np.cumsum(v));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dca4ed2-6030-49f4-86e3-69e9d9c2c319",
   "metadata": {},
   "source": [
    "# Ejercicio 2 Segmentación de imágenes con K-Means\n",
    "\n",
    "Hemos hablado de los beneficios de varios algoritmos para segmentación de imágenes, como es el caso de `meanshift`.\n",
    "Para el siguiente ejemplo, debes implementar segmentación de imágenes utilizando nuestro algoritmo más básico de agrupamiento.\n",
    "Utilizar la imágen `./data/montevideo.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f682b4-3022-4c61-91ad-f59e72053ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline\n",
    "from scipy import ndimage\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba99c99-1f6c-47a4-95db-4ce426a4d4b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pic = plt.imread()/255  #TODO dividing by 255 to bring the pixel values between 0 and 1\n",
    "print(pic.shape)\n",
    "plt.imshow() #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bbb89b-ba14-498c-90f3-a174ba855d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pic_n = pic.reshape() #TODO\n",
    "pic_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e475d5-5aae-4bd0-ac85-6ed50a2cee07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO - Plot del codo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855bd98e-b3a6-452c-b7b2-c31260f2a923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tomar el valor k resultante del plot anterior.\n",
    "# Probar otros valores de K para ver su resultado\n",
    "kmeans = KMeans().fit() #TODO\n",
    "pic2show = kmeans.cluster_centers_[] #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2791b9e-70e7-4fa9-9b4a-1502eef062c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_pic = pic2show.reshape() #TODO\n",
    "plt.imshow() #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac56ab9-7972-4f7e-aaa7-302db77c97f1",
   "metadata": {},
   "source": [
    "# Ejercicio 3 - GAN\n",
    "\n",
    "Importar el dataset de `CIFAR10 data` y construir un generador.\n",
    "\n",
    "[Información del dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    ">Note: Se recomienda ejecutar todo el notebook o a partir de este ejercicio en COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dce8bc-2c85-47b5-96fe-7a0c7ab9ee6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "import keras\n",
    "from keras import layers\n",
    "import os\n",
    "#from keras.preprocessing import image\n",
    "from keras.utils import load_img, img_to_array\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ec067-3d33-4b4f-beac-b48ec00ed03d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "# First, transform the input into a 16x16 128-channels feature map\n",
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.()()#TODO Completar la función de activación luego del . y el último paréntisis \n",
    "x = layers.Reshape((16, 16, 128))()#TODO\n",
    "\n",
    "# Then, add a convolution layer\n",
    "x = layers.Conv2D(256, 5, padding='same')()#TODO\n",
    "x = layers.()() #TODO Completar la función de activación luego del . y el último paréntisis\n",
    "\n",
    "# Upsample to 32x32\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')()#TODO\n",
    "x = layers.()()#TODO Completar la función de activación luego del . y el último paréntisis\n",
    "\n",
    "# Few more conv layers\n",
    "x = layers.Conv2D(256, 5, padding='same')()#TODO\n",
    "x = layers.()() #TODO Completar la función de activación luego del . y el último paréntisis\n",
    "x = layers.Conv2D(256, 5, padding='same')()#TODO\n",
    "x = layers.()()#TODO Completar la función de activación luego del . y el último paréntisis\n",
    "\n",
    "# Produce a 32x32 1-channel feature map\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')()#TODO\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c99a9-0b8e-4098-8d34-ae384f5e0a61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.()()#TODO Completar la función de activación luego del . y el último paréntisis\n",
    "x = layers.Conv2D(128, 4, strides=2)()#TODO\n",
    "x = layers.()()#TODO Completar la función de activación luego del . y el último paréntisis\n",
    "x = layers.Conv2D(128, 4, strides=2)()#TODO\n",
    "x = layers.()()#TODO Completar la función de activación luego del . y el último paréntisis\n",
    "x = layers.Conv2D(128, 4, strides=2)()#TODO\n",
    "x = layers.()()#TODO Completar la función de activación luego del . y el último paréntisis\n",
    "x = layers.Flatten()() #TODO\n",
    "\n",
    "# One dropout layer - important trick!\n",
    "x = layers.Dropout(0.4)()#TODO\n",
    "\n",
    "# Classification layer\n",
    "x = layers.Dense(1, activation='')() #TODO\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "\n",
    "# To stabilize training, we use learning rate decay\n",
    "# and gradient clipping (by value) in the optimizer.\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4fd57e-48aa-4ecf-9a0e-4453d702aef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set discriminator weights to non-trainable\n",
    "# (will only apply to the `gan` model)\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc25c3-4584-49dc-982b-d4d886c40176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 data\n",
    "(x_train, y_train), (_, _) = #TODO\n",
    "\n",
    "# Select frog images (class 6)\n",
    "x_train = x_train[y_train.flatten() == 6]\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train.reshape(\n",
    "    (x_train.shape[0],) + (height, width, channels)).astype('float32') / 255.\n",
    "\n",
    "iterations = 1000\n",
    "batch_size = 20\n",
    "save_dir = '.data/output/gan_images/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Start training loop\n",
    "start = 0\n",
    "for step in range(iterations):\n",
    "    # Sample random points in the latent space\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "    # Decode them to fake images\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "\n",
    "    # Combine them with real images\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "\n",
    "    # Assemble labels discriminating real from fake images\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    # Add random noise to the labels - important trick!\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "\n",
    "    # Train the discriminator\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "\n",
    "    # sample random points in the latent space\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "    # Assemble labels that say \"all real images\"\n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "\n",
    "    # Train the generator (via the gan model,\n",
    "    # where the discriminator weights are frozen)\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "      start = 0\n",
    "\n",
    "    # Occasionally save / plot\n",
    "    if step % 100 == 0:\n",
    "        # Save model weights\n",
    "        gan.save_weights('.data/output/gan.h5')\n",
    "\n",
    "        # Print metrics\n",
    "        print('discriminator loss at step %s: %s' % (step, d_loss))\n",
    "        print('adversarial loss at step %s: %s' % (step, a_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6093f8-56ac-4983-aab8-63be637d5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample random points in the latent space\n",
    "random_latent_vectors = np.random.normal(size=(10, latent_dim))\n",
    "\n",
    "# Decode them to fake images\n",
    "generated_images = generator.predict(random_latent_vectors)\n",
    "\n",
    "for i in range(generated_images.shape[0]):\n",
    "    img = image.array_to_img(generated_images[i] * 255., scale=False)\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6252384-871f-40ad-8a1f-84a36b7eb4d2",
   "metadata": {},
   "source": [
    "# Ejercicio 4 - VAE (Opcional)\n",
    "\n",
    "Tomando cualquier dataset que desees, implementa tu `VAE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5d5cc0-c7b8-4295-94f6-233c1405d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f8d02-f208-45f5-a58c-c1e7471cbff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba666eb2-035e-469b-abc4-a96fa67b7c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
