{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee62319-fcfc-4e02-b4b5-3e90dc00d4f1",
   "metadata": {},
   "source": [
    "# Ejercicio: Eigenfaces\n",
    "\n",
    "Anteriormente exploramos un ejemplo del uso de una proyección PCA como selector de funciones para el reconocimiento facial con una máquina de vectores de soporte.\n",
    "Aquí echaremos un vistazo atrás y exploraremos un poco más de lo que sucedió. Recuerde que estábamos utilizando el conjunto de datos Labeled Faces in the Wild (LFW) disponible a través de Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6648763-52c2-428a-9c93-4c84b42974fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c78859-9bb7-4daf-b16e-5600efe99641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "X,y=#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1074620-2171-47b6-ba79-5397d398080d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit()#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12055f95-3022-4b2b-9a9d-8443e4487e60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lista el ratio de varianza\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef55225-7020-4f3e-a423-ada128c32661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotear la varianza explicada y determinar la cantidad de componentes\n",
    "# a utilizar que mejor expliquen los datos\n",
    "\n",
    "plt.plot(np.cumsum()) #TODO - Varianza\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6160074-baba-499b-862b-173b1a9d5642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca = PCA(, \n",
    "          svd_solver='randomized', \n",
    "          random_state=42) #TODO agragar la cantida de componentes estimados que mejor expliquen los datos en base al plot anterior\n",
    "pca.fit() #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56cd12-7c78-448f-a380-4a78d438f389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 8, figsize=(9, 4),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(pca.components_[i].reshape(62, 47), cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fea3c9-35d5-4ee5-a260-946a44e1b6eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the components and projected faces\n",
    "pca = pca.fit()#TODO\n",
    "components = pca.transform()#TODO\n",
    "projected = pca.inverse_transform()#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3685aa5c-bd11-4019-897d-2b35084dfb21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot los resultados comparando los datos de entrada\n",
    "# con los las imagenes en un espacio de dimensiones menor.\n",
    "\n",
    "fig, ax = plt.subplots(2, 10, figsize=(10, 2.5),\n",
    "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i in range(10):\n",
    "    ax[0, i].imshow(X[i].reshape(62, 47), cmap='binary_r')\n",
    "    ax[1, i].imshow(projected[i].reshape(62, 47), cmap='binary_r')\n",
    "    \n",
    "ax[0, 0].set_ylabel('full-dim\\nentrada')\n",
    "ax[1, 0].set_ylabel('150-dim\\nreconstrucción');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb6a766-31ae-479e-a250-ac05f282ec6c",
   "metadata": {},
   "source": [
    "# Ejercicio 2 PCA en MNIST Dataset\n",
    "\n",
    "El conjunto de datos MNIST se compone de imágenes de `28x28` píxeles de dígitos escritos a mano. Normalmente, cuando se entrenan modelos de aprendizaje automático, MNIST se vectoriza considerando todos los píxeles como un vector de `784` dimensiones o, en otras palabras, colocando todos los píxeles de `28x28` uno al lado del otro en una matriz de `1x784`. No muchos conjuntos de datos son mayores que `784D` (dimensiones), y si alguna vez ha trabajado con conjuntos de datos de alta dimensión, sabemos que el tiempo de entrenamiento y el tiempo de predicción son proporcionales al tamaño del conjunto de datos y la cantidad de características (dimensionalidad).\n",
    "Dimensionalidad\n",
    "\n",
    "Antes de continuar, deberíamos tener una pequeña discusión sobre la dimensionalidad y por qué es importante. En términos simplistas, es solo el número de columnas en el conjunto de datos, pero tiene importantes efectos posteriores en los modelos finales. En los extremos, el concepto de `maldición de la dimensionalidad` analiza que en espacios de alta dimensión algunas cosas simplemente dejan de funcionar correctamente. \n",
    "\n",
    "Incluso en problemas de dimensiones relativamente bajas, un conjunto de datos con más dimensiones requiere más parámetros para que el modelo los comprenda, y eso significa más filas para aprender esos parámetros de manera confiable. Si el número de filas en el conjunto de datos es fijo, agregar dimensiones adicionales sin agregar más información para que los modelos aprendan puede tener un efecto perjudicial en la precisión final del modelo.\n",
    "\n",
    "Echemos un vistazo a cuánto tiempo lleva entrenar un clasificador gaussiano en el conjunto de datos MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d5b3a-032c-4d21-b96c-08d0a491618d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#to load MNIST - popular dataset of written digits\n",
    "from sklearn.datasets import load_digits as LoadData "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca10526b-7b29-4c9d-977e-b2adfc072266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let's load the data - it is pretty high-dimensional(64 features, each image of digit is 8x8)\n",
    "X, y = LoadData(n_class=10, return_X_y = True, as_frame = True)\n",
    "print(X.shape) #printing its shape\n",
    "X.head(5) #and the first 5 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300cba3d-358c-4b9a-985c-548fc8a0ea2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let's print a digit\n",
    "print(np.array(X.iloc[9]).reshape(8,8))\n",
    "plt.imshow(np.array(X.iloc[9]).reshape(8,8), cmap = 'binary', interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d323547-c875-463f-be0a-6dff30a5d918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA() #TODO - Utilizar valor porcentual - Ejemplo, 0.8, 0.9\n",
    "X_reduced = pca.fit_transform() #TODO\n",
    "print(X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317689dd-1f78-439b-8647-9d6b9b2d0016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Now let's recover out original data from compressed and recognise the same digit we had!\n",
    "#We can recognise it because the amount of varience dropped was pretty small, so the recovered version is almost the same. \n",
    "X_recovered = pca.inverse_transform() #TODO\n",
    "plt.imshow(X_recovered[9].reshape(8,8), cmap = 'binary', interpolation = 'bilinear')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
